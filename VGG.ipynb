{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as f\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG 16\n",
    "#### Very Deep Convolutional Network For Large Scale Image Recognition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Paper \n",
    "\n",
    "https://arxiv.org/pdf/1409.1556"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Input Image --- > (224 X 224 X 3)\n",
    "Kernel Size ----> (3 x 3)\n",
    "Max-Pooling ----> (2x2 , Stride = 2)\n",
    "Hidden Layer Activation --> Relu \n",
    "Output Layer Activation --> Softmax\n",
    "VGG-16 ---> (16Conv and 3FC Layers)\n",
    "Number of Parameters ----> 138 Millions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"VGG16.png\" width=600 height=60 />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=64,kernel_size=3,padding=1,stride=1)\n",
    "        self.conv2=nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,padding=1,stride=1)\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.conv3=nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,padding=1,stride=1)\n",
    "        self.conv4=nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,padding=1,stride=1)\n",
    "\n",
    "        self.conv5=nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,padding=1,stride=1)\n",
    "        self.conv6=nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,padding=1,stride=1)\n",
    "\n",
    "        self.conv7=nn.Conv2d(in_channels=256,out_channels=512,kernel_size=3,padding=1,stride=1)\n",
    "        self.conv8=nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3,padding=1,stride=1)\n",
    "        \n",
    "        self.fc1=nn.Linear(in_features=25088,out_features=4096)\n",
    "        self.fc2=nn.Linear(in_features=4096,out_features=4096)\n",
    "        self.fc3=nn.Linear(in_features=4096,out_features=1000)\n",
    "        self.dropout=nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # conv3-64\n",
    "        x=f.relu(self.conv1(x))\n",
    "        x=f.relu(self.conv2(x))\n",
    "        \n",
    "        x=self.maxpool(x)\n",
    "        \n",
    "        # conv3-128\n",
    "        x=f.relu(self.conv3(x))\n",
    "        x=f.relu(self.conv4(x))\n",
    "        \n",
    "        x=self.maxpool(x)\n",
    "        \n",
    "        # conv3-256\n",
    "        x=f.relu(self.conv5(x))\n",
    "        x=f.relu(self.conv6(x))\n",
    "        x=f.relu(self.conv6(x))\n",
    "        \n",
    "        x=self.maxpool(x)\n",
    "        \n",
    "        # conv3-512\n",
    "        x=f.relu(self.conv7(x))\n",
    "        x=f.relu(self.conv8(x))\n",
    "        x=f.relu(self.conv8(x))\n",
    "        \n",
    "        x=self.maxpool(x)\n",
    "        \n",
    "        # conv3-512\n",
    "        x=f.relu(self.conv8(x))\n",
    "        x=f.relu(self.conv8(x))\n",
    "        x=f.relu(self.conv8(x))\n",
    "        \n",
    "        x=self.maxpool(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        x=x.reshape(-1,25088)\n",
    "        x=f.relu(self.fc1(x))\n",
    "        x=self.dropout(x)\n",
    "        x=f.relu(self.fc2(x))\n",
    "        x=self.dropout(x)\n",
    "        x=f.relu(self.fc2(x))\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=VGG16()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 7, 7])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "            Conv2d-2         [-1, 64, 224, 224]          36,928\n",
      "         MaxPool2d-3         [-1, 64, 112, 112]               0\n",
      "            Conv2d-4        [-1, 128, 112, 112]          73,856\n",
      "            Conv2d-5        [-1, 128, 112, 112]         147,584\n",
      "         MaxPool2d-6          [-1, 128, 56, 56]               0\n",
      "            Conv2d-7          [-1, 256, 56, 56]         295,168\n",
      "            Conv2d-8          [-1, 256, 56, 56]         590,080\n",
      "            Conv2d-9          [-1, 256, 56, 56]         590,080\n",
      "        MaxPool2d-10          [-1, 256, 28, 28]               0\n",
      "           Conv2d-11          [-1, 512, 28, 28]       1,180,160\n",
      "           Conv2d-12          [-1, 512, 28, 28]       2,359,808\n",
      "           Conv2d-13          [-1, 512, 28, 28]       2,359,808\n",
      "        MaxPool2d-14          [-1, 512, 14, 14]               0\n",
      "           Conv2d-15          [-1, 512, 14, 14]       2,359,808\n",
      "           Conv2d-16          [-1, 512, 14, 14]       2,359,808\n",
      "           Conv2d-17          [-1, 512, 14, 14]       2,359,808\n",
      "        MaxPool2d-18            [-1, 512, 7, 7]               0\n",
      "           Linear-19                 [-1, 4096]     102,764,544\n",
      "          Dropout-20                 [-1, 4096]               0\n",
      "           Linear-21                 [-1, 4096]      16,781,312\n",
      "          Dropout-22                 [-1, 4096]               0\n",
      "           Linear-23                 [-1, 4096]      16,781,312\n",
      "================================================================\n",
      "Total params: 151,041,856\n",
      "Trainable params: 151,041,856\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 115.19\n",
      "Params size (MB): 576.18\n",
      "Estimated Total Size (MB): 691.94\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,(3, 224, 224),batch_size=-1,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python37864bit3efe367894924a36a499243ba95600f9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
